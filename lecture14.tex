% Copyright Luke Olson 2009--2014
% This work is licensed under the Creative Commons
% Attribution-NonCommercial-NoDerivatives 4.0 International License. To view a
% copy of this license, visit http://creativecommons.org/licenses/by-nc-nd/4.0/.
%
\documentclass[10pt]{beamer}
%\documentclass[handout,10pt]{beamer}
%
\mode<presentation>
{
  \usetheme[secheader]{Boadilla}
  \usefonttheme[onlymath]{serif}
  \setbeamercovered{invisible}
  \usecolortheme{luke}
  %\setbeamercovered{transparent}
  %
}
\mode<handout>
{
  \usetheme[secheader]{Boadilla}
  \usefonttheme[onlymath]{serif}
  \setbeamercovered{invisible}
  \usecolortheme{luke2}
  %\setbeamercovered{transparent}
}
\usepackage{pgf,pgfarrows,pgfnodes,pgfautomata,pgfheaps,pgfshade}
\usepackage{pxfonts}
\usepackage{eulervm}
\usepackage{listings}
%\usepackage{pgfpages}
%\pgfpagesuselayout{2 on 1}[letterpaper]
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%
%
%
\newcommand{\vb}{{\bf{b}}}
\newcommand{\ve}{{\bf{e}}}
\newcommand{\vg}{{\bf{g}}}
\newcommand{\vp}{{\bf{p}}}
\newcommand{\vr}{{\bf{r}}}
\newcommand{\vu}{{\bf{u}}}
\newcommand{\vx}{{\bf{x}}}
\newcommand{\vz}{{\bf{z}}}
\newcommand{\vA}{{\bf{A}}}
\newcommand{\vU}{{\bf{U}}}
\newcommand{\mO}{{\mathcal{O}}}
\newcommand{\mF}{{\mathcal{F}}}
\definecolor{mygray}{rgb}{0.95,0.95,0.95}
\lstset{
        language=matlab,
        numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=5pt,
        basicstyle=\color{black}\ttfamily\small,
        commentstyle=\color{green}\ttfamily,
        keywordstyle=\color{blue}\ttfamily,
        stringstyle=\color{red}\ttfamily,
        showstringspaces=false,
        backgroundcolor=\color{mygray},
        breaklines,
}
\newcommand{\norm}[1]{{\ensuremath{{\|#1\|}}}}
\newcommand{\matdim}[2]{\ensuremath{#1\times#2}}
\newcommand{\rank}[1]{\ensuremath{\mathrm{rank}(#1)}}
\newcommand{\epsm}{\ensuremath{\varepsilon_m}}
\newcommand{\cmd}[1]{{\normalfont\ttfamily\bfseries#1}}

\author{L. Olson}
\institute[UIUC]
{Department of Computer Science\\
University of Illinois at Urbana-Champaign\\
\vspace{0.5cm}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pgfdeclareimage[height=0.5cm]{university-logo}{./figs/uiuclogo}
\logo{\pgfuseimage{university-logo}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title[CS 357]{Lecture 14}
\subtitle{Roots of Polynomials; Interpolation}
\date{October 13, 2009}

\begin{document}
% -------------------------------------------------
\begin{frame}
  \titlepage
\end{frame}
% -------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Roots of Polynomials}

Complications arise due to
\begin{itemize}
    \item   Repeated roots
    \item   Complex roots
    \item   Sensitivity of roots to small perturbations
            in the polynomial coefficients (conditioning).
\end{itemize}
\vspace{4ex}

\centerline{\pgfimage[height=3cm]{./figs/polyRootsPlot}}


% ------------
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Algorithms for Finding Polynomial Roots}

\begin{itemize}
    \item   Bairstow's method
    \item   M\"{u}ller's method
    \item   Laguerre's method
    \item   Jenkin's--Traub method
    \item   Companion matrix method
\end{itemize}

% ------------
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
\frametitle{\texttt{roots} Function}

The built-in \texttt{roots} function in MATLAB uses the companion matrix method
\begin{itemize}
    \item   No initial guess
    \item   Returns \emph{all} roots of the polynomial
    \item   Solves \emph{eigenvalue problem} for companion matrix
\end{itemize}

\vspace{4ex}
Write polynomial in the form
\begin{equation*}
    c_1 x^n + c_2 x^{n-1} + \ldots + c_n x + c_{n+1} = 0
\end{equation*}
Then, for a \emph{third} order polynomial
\begin{lstlisting}[language=matlab]
>> c = [c1 c2 c3 c4];
>> r = roots(c)
\end{lstlisting}

% ------------
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile,shrink]
\frametitle{\texttt{roots} Function}

The eigenvalues of
\begin{equation*}
    A = \begin{bmatrix} 0 & 1 & 0 & 0 \\
                        0 & 0 & 1 & 0 \\
                        0 & 0 & 0 & 1 \\
                       -c_0 & -c_1 & -c_2 & -c_3 \end{bmatrix}
\end{equation*}
are the same as the roots of
\begin{equation*}
    \lambda^4 + c_3 \lambda^3 + c_2 \lambda^2 + c_1 \lambda + c_0 = 0.
\end{equation*}
To see this, recall $Ax = \lambda x$ is the equation satisfied by
eigenvalues $\lambda$ of $A$.  Write this as $(A - I\lambda)x = 0$.

Then the matrix
\begin{equation*}
    A -\lambda I= 
       \begin{bmatrix} -\lambda & 1 & 0 & 0 \\
                        0 & -\lambda & 1 & 0 \\
                        0 & 0 & -\lambda & 1 \\
                       -c_0 & -c_1 & -c_2 & (-c_3 - \lambda)\end{bmatrix}
\end{equation*}
is
singular, and the determinant is zero.  Because most of the entries of
this matrix are zero, the determinant can be computed.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile,shrink]
\frametitle{Finding \texttt{roots} in MATLAB}

\vspace{2ex}
The statements
\begin{lstlisting}[language=matlab]
c = ...      %  vector of polynomial coefficients
r = roots(c);
\end{lstlisting}
are equivalent to
\begin{lstlisting}[language=matlab]
c = ...
n = length(c);
A = diag(ones(1,n-2),1);   %  ones on first superdiagonal
A(n,:) = -c(1:n-1) ./ c(n);   %  last row is -c(j)/c(n), j=1..n-1
r = eig(A);
\end{lstlisting}

% ------------
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile,shrink]
\frametitle{\texttt{roots} Examples}

Roots of
\begin{align*}
    f_1(x) &= x^2 -  3x +  2    \\
    f_2(x) &= x^2 - 10x + 25    \\
    f_3(x) &= x^2 - 17x + 72.5
\end{align*}
are found with
\begin{lstlisting}[language=matlab]
>> roots([1 -3 2])
ans =
        2
        1

>> roots([1 -10 25])
ans =
        5
        5

>> roots([1 -17 72.5])
ans =
    8.5000 + 0.5000i
    8.5000 - 0.5000i
\end{lstlisting}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Next Topics}

\begin{enumerate}
  \item Interpolation: Approximating a function $f(x)$ by a polynomial
$p_n(x)$.
  \item Differentiation: Approximating the derivative of a function
$f(x)$.
  \item Integration: Approximating an integral $\int_a^b f(x)\,dx$
\end{enumerate}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Interpolation: Introduction}
  \begin{block}{Objective}
    Approximate an unknown function $f(x)$ by an easier function $g(x)$,
such as a polynomial. 
  \end{block}
  \begin{block}{Objective (alt)}
  Approximate some data by a function $g(x)$. 
  \end{block}
Types of approximating functions:
\begin{enumerate}
  \item Polynomials
  \item Piecewise polynomials
  \item Rational functions
  \item Trig functions
  \item Others (inverse, exponential, Bessel, etc)
\end{enumerate}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Interpolation: Introduction}
How do we approximate $f(x)$ by $g(x)$?  In what sense is the
approximation a good one? 
\begin{enumerate}
  \item Interpolation: $g(x)$ must have the same values of $f(x)$ at set
of given points.
  \item Least-squares: $g(x)$ must deviate as little as possible from
$f(x)$ in the sense of a 2-norm:  minimize $\int_{a}^b |f(t)-g(t)|^2\,dt$
  \item Chebyshev: $g(x)$ must deviate as little as possible from $f(x)$
in the sense of the $\infty$-norm: minimize $\max_{t\in[a,b]}
|f(t)-g(t)|$.
\end{enumerate}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Interpolation: Introduction}
  \begin{block}{}
    Given $n+1$ distinct points $x_0,\dots,x_n$, and values
$y_0,\dots,y_n$, find a polynomial $p(x)$ of degree $n$ so that
  \begin{equation*}
    p(x_i) = y_i\quad i=0,\dots,n
\end{equation*}
  \end{block}
\begin{itemize}
  \item A polynomial of degree $n$ has $n+1$ degrees-of-freedom:
\begin{equation*}
  p(x) = a_0 + a_1 + \dots + a_n x^n
\end{equation*}
\item $n+1$ constraints determine the polynomial uniquely:
\begin{equation*}
  p(x_i) = y_i, \quad i=0,\dots,n
\end{equation*}
\begin{block}{Theorem (page 128 6thEd)}
  If points $x_0,\dots,x_n$ are distinct, then for arbitrary $y_0,\dots,y_n$,
there is a \emph{unique} polynomial $p(x)$ of degree at most $n$ such that
$p(x_i)=y_i$ for $i=0,\dots,n$.
\end{block}
\end{itemize}
\begin{alertblock}{}
How can you prove the polynomial is unique?  (Hint: What if it isn't?)
\end{alertblock}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Monomials}
  Obvious attempt: try picking
  \begin{equation*}
    p(x) = a_0 + a_1 x + a_2 x^2 +\dots + a_{n} x^{n}
  \end{equation*}
  So for each $x_i$ we have
  \begin{align*}
    p(x_i) = a_0 + a_1 x_i + a_2 x_i^2 +\dots + a_{n} x_i^{n} & = y_i
  \end{align*}
  OR
  \begin{align*}
    a_0 + a_1 x_0 + a_2 x_0^2 +\dots + a_{n} x_0^{n} & = y_0\\
    a_0 + a_1 x_1 + a_2 x_1^2 +\dots + a_{n} x_1^{n} & = y_1\\
    a_0 + a_1 x_2 + a_2 x_2^2 +\dots + a_{n} x_2^{n} & = y_2\\
    a_0 + a_1 x_3 + a_2 x_3^2 +\dots + a_{n} x_3^{n} & = y_3\\
    \vdots &\\
    a_0 + a_1 x_n + a_2 x_n^2 +\dots + a_{n} x_n^{n} & = y_n\\
  \end{align*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Monomial: The problem}
  \begin{align*}
    \begin{bmatrix}
      1 & x_0 & x_0^2 & \dots & x_0^{n}\\
      1 & x_1 & x_1^2 & \dots & x_1^{n}\\
      1 & x_2 & x_2^2 & \dots & x_2^{n}\\
        &     &       & \vdots&      \\
      1 & x_n & x_n^2 & \dots & x_n^{n}\\
    \end{bmatrix}
    \begin{bmatrix}
      a_0\\
      a_1\\
      a_2\\
      \vdots\\
      a_n\\
    \end{bmatrix}
    \begin{bmatrix}
      y_0\\
      y_1\\
      y_2\\
      \vdots\\
      y_n\\
    \end{bmatrix}
  \end{align*}
  \begin{block}{Question}
    \begin{itemize}
      \item Is this a ``good'' system to solve? 
    \end{itemize}
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
\frametitle{Example}
\framesubtitle{from Recktenwald}
Consider Gas prices (in cents) for the following years:
\begin{tabular}{c | c | l l l l l l}
$x$ & year  & 1986 & 1988 & 1990 & 1992 & 1994 & 1996 \\\hline
$y$ & price & 133.5& 132.2& 138.7& 141.5& 137.6& 144.2\\
\end{tabular}
\begin{lstlisting}
year =[1986   1988   1990   1992   1994   1996 ]';
price=[133.5  132.2  138.7  141.5  137.6  144.2]';

M = vander(year);
a = M\price;

x=linspace(1986,1996,200);
p=polyval(a,x);
plot(year,price,'o',x,p,'-');
\end{lstlisting}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Back to the basics...}
  \begin{example}
Find the interpolating polynomial of least degree
that interpolates
\begin{center}
  \begin{tabular}{c | c c}
  $x$ & 1.4 & 1.25 \\\hline
  $y$ & 3.7 & 3.9 \\
  \end{tabular}
\end{center}
\end{example}
Directly
  \begin{align*}
    p_1(x) & = \left(\frac{x-1.25}{1.4-1.25}\right) 3.7 +
    \left(\frac{x-1.4}{1.25 - 1.4}\right) 3.9\\
    & =  3.7 + \left(\frac{3.9-3.7}{1.25-1.4}\right)(x-1.4)\\
    & = 3.7 - \frac{4}{3}(x-1.4)\\
  \end{align*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Lagrange}
What have we done?  We've written $p(x)$ as
\begin{equation*} 
  p(x) = \left(\frac{x-x_1}{x_0-x_1}\right) y_0 + 
         \left(\frac{x-x_0}{x_1-x_0}\right) y_1
\end{equation*}
\begin{itemize}
  \item the sum of two linear polynomials
  \item the first is zero at $x_1$ and 1 at $x_0$
  \item the second is zero at $x_0$ and 1 at $x_1$
  \item these are the two linear Lagrange basis functions:
\begin{equation*}
  \ell_0(x) = \frac{x-x_1}{x_0-x_1}\qquad \ell_1(x) =\frac{x-x_0}{x_1-x_0}
\end{equation*}
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Lagrange}
\begin{example}
  Write the Lagrange basis functions for 
\begin{center}
  \begin{tabular}{c | c c c}
  $x$ & $\frac{1}{3}$ & $\frac{1}{4}$ & 1\\\hline
  $y$ & 2 & -1 & 7 \\
  \end{tabular}
\end{center}
\end{example}
Directly
\begin{align*}
  \ell_0(x) & = \frac{(x-\frac{1}{4})(x-1)}{(\frac{1}{3} -\frac{1}{4})(\frac{1}{3} - 1)}\\
  \ell_1(x) & = \frac{(x-\frac{1}{3})(x-1)}{(\frac{1}{4} -\frac{1}{3})(\frac{1}{4} - 1)}\\
  \ell_2(x) & = \frac{(x-\frac{1}{3})(x-\frac{1}{4})}{(1 -\frac{1}{3})(1-\frac{1}{4})}\\
\end{align*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Lagrange}
The general Lagrange form is
\begin{equation*}
  \ell_k(x) = \prod_{i=0,i\ne k}^{n} \frac{x-x_i}{x_k - x_i}
\end{equation*}
The resulting interpolating polynomial is
\begin{equation*}
  p(x) = \sum_{k=0}^n \ell_k(x) y_k
\end{equation*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Example}
Find the equation of the parabola passing through the points
(1,6), (-1,0), and (2,12)

\begin{block}{}
$ x_0 = 1, x_1 = -1, x_2 = 2; \qquad y_0 = 6, y_1 = 0, y_2 = 12; $
\end{block}
\[
\begin{array}{llll} 
\ell_0 (x) & = & \frac{(x-x_1)(x-x_2)}{(x_0-x_1)(x_0-x_2)} & 
        = \frac{(x+1)(x-2)}{(2)(-1) } \\
\ell_1 (x) & = & \frac{(x-x_0)(x-x_2)}{(x_1-x_0)(x_1-x_2)} & 
        = \frac{(x-1)(x-2)}{(-2)(-3) } \\
\ell_2 (x) & = & \frac{(x-x_0)(x-x_1)}{(x_2-x_0)(x_2-x_1)} & 
        = \frac{(x-1)(x+1)}{(1)(3) } \\
\end{array} 
\] 

\begin{eqnarray*} 
p_2(x)  & = & y_0 \ell_0(x) + y_1 \ell_1(x) + y_2 \ell_2(x) \\ 
        & = & -3 \times (x+1)(x-2) + 0 \times {1\over 6} (x-1)(x-2) \\
& & \ + 4 \times (x-1)(x+1) \\
 & = & (x+1) [ 4 (x-1) - 3 (x-2) ] \\
 & =  & (x+1) (x + 2 ) 
\end{eqnarray*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Summary so far:}
\begin{itemize}
  \item Monomials: $p(x) = a_0 + a_1 x +\dots+a_n x^n$ results in poor
conditioning
  \item Monomials: but evaluating the Monomial interpolant is cheap
(nested iteration)
  \item Lagrange: $p(x) = \ell_0(x) y_0 + \dots + \ell_n(x) y_n$ is very
well behaved.
  \item Lagrange: but evaluating the Lagrange interpolant is expensive
(each basis function is of the same order and the interpolant is not
easily reduced to nested form)
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Fixing Monomials, Fixing Lagrange}
Back to the gas price example.  Suppose we use a better basis like
\begin{equation*}
  (x-\bar{x})^k
\end{equation*}
instead of
\begin{equation*}
  x^k
\end{equation*}
For example, $\bar{x} = average(x_i), i=0,\dots,n$.

The basis $(x-\bar{x})^k$ are called \emph{shifted monomials} because
$x$ is shifted by $\bar{x}$.
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Recall Nested Form}
Given a polynomial
\begin{equation*}
  p(x) = -5 + 4x -7x^2 + 2x^3 + 3x^4
\end{equation*}
we can write this as
\begin{equation*}
  p(x) = -5 + x(4 + x(-7 + x(2 + 3x)));
\end{equation*}
evaluation can be done from the inside-out, for cheap (nested
evaluation).  This polynomial can also be written as
\begin{equation*}
  p(x) = -5 + 2x - 4x(x-1) + 8x(x-1)(x+1) + 3x(x-1)(x+1)(x-2)
\end{equation*}
in nested form
\begin{equation*}
  p(x) = -5 + x(2 + (x-1)(-4 + (x+1)(8 + 3(x-2))))
\end{equation*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Newton Polynomials}
\begin{itemize}
\item Newton Polynomials are of the form
  \begin{equation*}
    p_n(x) = a_0 + a_1(x-x_0) + a_2(x-x_0)(x-x_1) + a_3(x-x_0)(x-x_1)(x-x_2) + \dots
  \end{equation*}

\item The basis used is thus
\begin{center}
  \begin{tabular}{l l}
  function & order \\
  $1$ & 0\\
  $x-x_0$ & 1\\
  $(x-x_0)(x-x_1)$ & 2\\
  $(x-x_0)(x-x_1)(x-x_2)$ & 3\\
  \end{tabular}
\end{center}

\item More stable that monomials
\item More computationally efficient (nested iteration) than using Lagrange
and shifted monomials
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Newton Polynomials using Divided Differences}
Consider the data
\begin{center}
  \begin{tabular}{c | c | c}
  $x_0$ & $x_1$ & $x_2$\\\hline
  $y_0$ & $y_1$ & $y_2$\\
  \end{tabular}
\end{center}
We want to find $a_0$, $a_1$, and $a_2$ in the following polynomial so that
it fits the data:
\begin{equation*}
  p_2(x) = a_0  + a_1(x-x_0) + a_2(x-x_0)(x-x_1)
\end{equation*}
Matching the data gives three equations to determine our three unknowns
$a_i$:
\begin{align*}
  \text{at $x_0$:\,\,} y_0 & = a_0 + 0 + 0\\
  \text{at $x_1$:\,\,} y_1 & = a_0 + a_1(x_1-x_0) + 0\\
  \text{at $x_2$:\,\,} y_2 & = a_0 + a_1(x_2-x_0) + a_2(x_2-x_0)(x_2-x_1)\\
\end{align*}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Newton Polynomials using Divided Differences}
Or in matrix form:
\begin{equation*}
  \begin{bmatrix}
    1 & 0 & 0\\
    1 & x_1 - x_0 & 0\\
    1 & x_2 - x_0 & (x_2-x_0)(x_2-x_1)\\
  \end{bmatrix}
  \begin{bmatrix}
    a_0\\ a_1\\ a_2\\
  \end{bmatrix}
  \begin{bmatrix}
    y_0\\ y_1\\ y_2\\
  \end{bmatrix}
\end{equation*}
$\Rightarrow$ lower triangular

$\Rightarrow$ only $\mO(n^2)$ operations

\begin{block}{Question}
How many operations are needed to find the coefficients in the
monomial basis?
\end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Newton Polynomials using Divided Differences}
Using Forward Substitution to solve this lower triangular system yields:
\begin{align*}
  a_0 & = y_0 = f(x_0)\\
  a_1 & = \frac{y_1 - a_0}{x_1 - x_0}\\
      & = \frac{f(x_1)-f(x_0)}{x_1 - x_0}\\
  a_2 & = \frac{y_2 - a_0 - (x_2-x_0)a_1}{(x_2-x_1)(x_2-x_0)}\\
      & = \frac{f(x_2)-f(x_0)-(x_2-x_0)\frac{f(x_1)-f(x_0)}{x_1-x_0}}{(x_2-x_1)(x_2-x_0)}\\
      & = \frac{\frac{f(x_2)-f(x_1)}{x_2-x_1} - \frac{f(x_1)-f(x_0)}{x_1-x_0} }{x_2-x_0}
\end{align*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Newton Polynomials using Divided Differences}
From this we see a pattern.   There are many terms of the form
\begin{equation*}
  \frac{f(x_j)-f(x_i)}{x_j-x_i}
\end{equation*}
These are called \emph{divided differences} and are denoted with square
brackets:
\begin{equation*}
  f[x_i,x_j] = \frac{f(x_j)-f(x_i)}{x_j-x_i}
\end{equation*}
Applying this to our results:
\begin{align*}
  a_0 & = f[x_0]\\
  a_1 & = f[x_0,x_1]\\
  a_2 & = \frac{f[x_1,x_2]-f[x_0,x_1]}{x_2-x_0}\\
      & = f[x_0,x_1,x_2]\\
\end{align*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[shrink]
\frametitle{Newton Polynomials using Divided Differences}
\framesubtitle{example: long way}
\begin{example}
  For the data
  \begin{center}
    \begin{tabular}{c | c c c}
      $x$ & 1 & -4 & 0\\\hline
      $y$ & 3 & 13 & -23\\
    \end{tabular}
  \end{center}
  Find the 2nd order interpolatin polynomial using Newton.
\end{example}
We know
\begin{equation*}
  p_1(x) = a_0  + a_1(x-x_0) + a_2(x-x_0)(x-x_1)
\end{equation*}
And that
\begin{align*}
  a_0 & = f[x_0] = f[1] = f(1) = 3\\
  a_1 & = f[x_0,x_1] = \frac{f(x_1)-f(x_0)}{x_1 - x_0} = \frac{13-3}{-4-1} =
  -2\\
  a_2 & = f[x_0,x_1,x_2] = \frac{f[x_1,x_2]-f[x_0,x_1]}{x_2-x_0}\\
      & = \frac{\frac{-23-13}{0--4} - \frac{13-3}{-4-1}}{0-1}\\
      & = \frac{-9+2}{-1} = 7
\end{align*}
So 
\begin{equation*}
  p_1(x) = 3 -2(x-1) + 7(x-1)(x+4)
\end{equation*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Divided Differences}
\begin{block}{Recursive Property}
  \begin{equation*}
    f[x_0,\dots,x_k] = \frac{f[x_1,\dots,x_k]-f[x_0,\dots,x_{k-1}]}{x_k -
    x_0}
  \end{equation*}
\end{block}
With the first two defined by
\begin{align*}
  f[x_i] &= f(x_i)\\
  f[x_i,x_j] &= \frac{f[x_j]-f[x_i]}{x_j-x_i}\\
\end{align*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Divided Differences}
\begin{block}{Invariance Theorem}
    $f[x_0,\dots,x_k]$ is invariant under all permutations of the arguments
    $x_0,\dots,x_k$
\end{block}
Simple ``proof'': $f[x_0,x_1,...,x_k]$ is the coefficient of the $x^k$
term in the polynomial interpolating $f$ at $x_0,\ldots,x_k$.  But any
permutation of the $x_i$ still gives the same polynomial.

This says that we can also write
  \begin{equation*}
    f[x_i,\dots,x_j] = \frac{f[x_{i+1},\dots,x_j]-f[x_i,\dots,x_{j-1}]}{x_j -
    x_i}
  \end{equation*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Divided Differences}
\framesubtitle{the easy way: tables}
We can compute the divided differences much easier using tables.  To
construct the divided difference table for $f(x)$ for the $x_0,\dots,x_3$
%\begin{tabular}{l!{\vrule}l<{\onslide<2->}l<{\onslide<3->}l<{\onslide<4->}l<{\onslide}l}
%\begin{tabular}{l!{\vrule}c<{\onslide<2->}c<{\onslide<3->}c<{\onslide}c}
\begin{center}
\begin{tabular}{l | l | l | l | l}
$x$ & $f[\cdot]$ & $f[\cdot,\cdot]$ & $f[\cdot,\cdot,\cdot]$ & $f[\cdot,\cdot,\cdot,\cdot]$\\\hline
\alt<2,5,7>{\color{red}$x_0$}{$x_0$}    & \alt<2>{\color{red}$f[x_0]$}{$f[x_0]$}&              &                  &                      \\
                                     &                                        & \alt<2,5>{\color{red}$f[x_0,x_1]$}{$f[x_0,x_1]$} &                  &                      \\
\alt<2,3,6>{\color{red}$x_1$}{$x_1$}  & \alt<2,3>{\color{red}$f[x_1]$}{$f[x_1]$} &              & \alt<5,7>{\color{red}$f[x_0,x_1,x_2]$}{$f[x_0,x_1,x_2]$} &                      \\ 
                                     &                                        & \alt<3,5,6>{\color{red}$f[x_1,x_2]$}{$f[x_1,x_2]$} &                  & \alt<7>{\color{red}$f[x_0,x_1,x_2,x_3]$}{$f[x_0,x_1,x_2,x_3]$} \\
\alt<3,4,5>{\color{red}$x_2$}{$x_2$}  & \alt<3,4>{\color{red}$f[x_2]$}{$f[x_2]$}   &              & \alt<6,7>{\color{red}$f[x_1,x_2,x_3]$}{$f[x_1,x_2,x_3]$} &                      \\
                                     &                                        & \alt<4,6>{\color{red}$f[x_2,x_3]$}{$f[x_2,x_3]$} &                  &                      \\
\alt<4,6,7>{\color{red}$x_3$}{$x_3$}  & \alt<4>{\color{red}$f[x_3]$}{$f[x_3]$} &              &                  &                      \\
\end{tabular}
\end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Divided Differences}
\framesubtitle{the easy way: example}
Construct the divided differences table for the data
\begin{center}
\begin{tabular}{c c c c c}
 $x$ & 1 & $\frac{3}{2}$ & 0 & 2\\
 $y$ & 3 & $\frac{13}{4}$ & 3 & $\frac{5}{3}$\\
\end{tabular}
\end{center}
and construct the largest order interpolating polynomial.

We can compute the divided differences much more easily using tables.  To
construct the divided difference table for $f(x)$ for the $x_0,\dots,x_3$
\begin{center}
\begin{tabular}{l | l | l | l | l}
$x$ & $f[\cdot]$ & $f[\cdot,\cdot]$ & $f[\cdot,\cdot,\cdot]$ & $f[\cdot,\cdot,\cdot,\cdot]$\\\hline
\alt<2,5,7>{\color{red}1}{1}    & \alt<2>{\color{red}3}{3}&              &                  &                      \\
                                     &                                        & \alt<2,5>{\color{red}$\frac{1}{2}$}{$\frac{1}{2}$} &                  &                      \\
\alt<2,3,6>{\color{red}$\frac{3}{2}$}{$\frac{3}{2}$}  & \alt<2,3>{\color{red}$\frac{13}{4}$}{$\frac{13}{4}$} &              & \alt<5,7>{\color{red}$\frac{1}{3}$}{$\frac{1}{3}$} &                      \\ 
                                     &            & \alt<3,5,6>{\color{red}$\frac{1}{6}$}{$\frac{1}{6}$} &                  & \alt<7>{\color{red}-2}{-2} \\
\alt<3,4,5>{\color{red}0}{0}  & \alt<3,4>{\color{red}3}{3}   &              & \alt<6,7>{\color{red}-$\frac{5}{3}$}{-$\frac{5}{3}$} &                      \\
                                     &                                        & \alt<4,6>{\color{red}-$\frac{2}{3}$}{-$\frac{2}{3}$} &                  &                      \\
\alt<4,6,7>{\color{red}2}{2}  & \alt<4>{\color{red}$\frac{5}{3}$}{$\frac{5}{3}$} &              &                  &                      \\
\end{tabular}
\end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Divided Differences}
\framesubtitle{the easy way: example}
\begin{center}
\begin{tabular}{l | l | l | l | l}
$x$              & $f[\cdot]$       & $f[\cdot,\cdot]$            & $f[\cdot,\cdot,\cdot]$ & $f[\cdot,\cdot,\cdot,\cdot]$\\\hline
{1}              & {\color{red}3}   &                             &                        &                      \\
                 &                  & {\color{red}$\frac{1}{2}$}  &                        &                      \\
{$\frac{3}{2}$}  & {$\frac{13}{4}$} &                             & {\color{red}$\frac{1}{3}$} &                      \\ 
                 &                  & {           $\frac{1}{6}$}  &                  &{\color{red}-2} \\
{0}              & {3}              &                             & {           -$\frac{5}{3}$} &                      \\
                 &                  & {           -$\frac{2}{3}$} &                        &                      \\
{2}              & {$\frac{5}{3}$}  &                             &                        &                      \\
\end{tabular}
\end{center}
The coeffiecients are readily available and we arrive at
\begin{equation*}
  p_2(x) = 3 + \frac{1}{2}(x-1) + \frac{1}{3}(x-1)(x-\frac{3}{2}) -
2(x-1)(x-\frac{3}{2})x
\end{equation*}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
